import google.generativeai as genai
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import streamlit as st
import config


# è¨­å®š
genai.configure(api_key=config.GEMINI_API_KEY)
model = genai.GenerativeModel(model_name='gemini-1.5-flash-latest')

def load_sentences():
    with open(config.DB_PATH, 'r', encoding='utf-8') as file:
        return [line.strip() for line in file if line.strip()]

def embed_sentences(sentences_list):
    return genai.embed_content(
        model="models/embedding-001",
        content=sentences_list,
        task_type="retrieval_document",
        title="æ–‡å­—åˆ—ãƒªã‚¹ãƒˆã®åŸ‹ã‚è¾¼ã¿",
    )['embedding']

def embed_query(query):
    return genai.embed_content(
        model="models/embedding-001",
        content=query,
        task_type="retrieval_document",
        title="å˜ä¸€æ–‡å­—åˆ—ã®åŸ‹ã‚è¾¼ã¿",
    )['embedding']

def get_top_n_sentences(query_embedding, embeddings, sentences_list, n=3):
    embeddings_array = np.array(embeddings)
    query_emb = np.array(query_embedding).reshape(1, -1)
    cos_similarities = cosine_similarity(query_emb, embeddings_array)
    top_n_indices = np.argsort(cos_similarities[0])[::-1][:n]
    return [sentences_list[i] for i in top_n_indices]

def generate_response(question, reference_info):
    return model.generate_content(
        f'æ¬¡ã®è³ªå•ã«å¯¾ã™ã‚‹ç­”ãˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼å‚è€ƒæƒ…å ±ãŒè³ªå•ã¨é–¢ä¿‚ã‚ã‚Šãã†ãªå ´åˆã¯å‚è€ƒæƒ…å ±ã‚’åˆ©ç”¨ã—ã¦ãã ã•ã„ï¼è³ªå•ï¼š{question} å‚è€ƒæƒ…å ±ï¼š{reference_info}'
    ).text

def init_page():
    st.set_page_config(
        page_title='RAGã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ‡ãƒ¢',
        page_icon="ğŸ§‘â€ğŸ’»"
    )
    st.header('RAGã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ‡ãƒ¢')

def main():
    init_page()
    sentences_list = load_sentences()
    embeddings = embed_sentences(sentences_list)
    
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        if message["role"] == "assistant":
            with st.chat_message('assistant'):
                st.markdown(message["content"])
        elif message["role"] == "user":
            with st.chat_message('user'):
                st.markdown(message["content"])

    if user_input := st.chat_input('è³ªå•ã‚’å…¥åŠ›ã—ã¦ä¸‹ã•ã„'):
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message('user'):
            st.markdown(user_input)
        with st.chat_message('assistant'):
            with st.spinner('Gemini is typing ...'):
                query_embedding = embed_query(user_input)
                top_sentences = get_top_n_sentences(query_embedding, embeddings, sentences_list)
                reference_info = " ".join(top_sentences)
                response_text = generate_response(user_input, reference_info)
                st.markdown(response_text)
        st.session_state.messages.append({"role": "assistant", "content": response_text})

if __name__ == '__main__':
    main()
